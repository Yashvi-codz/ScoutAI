# -*- coding: utf-8 -*-
"""FINAL : SCOUT AI ( SynapseAI ).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ukiCNXlsBSkl-5Dm5TvHHwYQZKCHhJ40
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import RFECV
from sklearn.metrics import r2_score, mean_squared_error

path = "/content/Dataset - players_22.csv"
df = pd.read_csv(path)

df.head()

df.shape

df.describe()

"""**Filter : Only Goalkeepers**

Selecting Relevant GK Features
"""

features = [
    "age",
    "height_cm",
    "weight_kg",

    "movement_sprint_speed",
    "movement_acceleration",
    "movement_agility",
    "movement_balance",
    "movement_reactions",

    "power_jumping",
    "power_stamina",
    "power_strength",

    "defending_standing_tackle",

    "goalkeeping_reflexes",
    "goalkeeping_diving",
    "goalkeeping_speed"
]

target = "overall"

df_gk = df[features + [target]]

"""Handling Missing Values"""

df_gk = df_gk.fillna(df_gk.median(numeric_only=True))

df_gk.shape

"""Correlation Check (For Presentation)"""

plt.figure(figsize=(10,8))
sns.heatmap(df_gk.corr(), cmap='coolwarm')
plt.title("GK Correlation Heatmap")
plt.show()

"""Split Features & Target"""

X = df_gk.drop("overall", axis=1)
y = df_gk["overall"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""Scaling"""

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""Model Selection"""

!pip install xgboost

import numpy as np
import pandas as pd

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor

from sklearn.model_selection import cross_validate
from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error

from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_validate

models = {
    "Linear Regression": LinearRegression(),
    "Ridge": Ridge(alpha=1.0),
    "Lasso": Lasso(alpha=0.01),
    "Decision Tree": DecisionTreeRegressor(random_state=42),
    "Random Forest": RandomForestRegressor(n_estimators=200, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(random_state=42),
    "XGBoost": XGBRegressor(
        n_estimators=300,
        learning_rate=0.05,
        max_depth=5,
        random_state=42,
        verbosity=0
    ),
    "SVR": SVR()
}

def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

scoring = {
    "r2": "r2",
    "mae": make_scorer(mean_absolute_error),
    "rmse": make_scorer(rmse)
}

results = []

for name, model in models.items():

    pipeline = Pipeline([
        ("scaler", StandardScaler()),
        ("model", model)
    ])

    cv_results = cross_validate(
        pipeline,
        X_train,
        y_train,
        cv=5,
        scoring=scoring,
        return_train_score=False
    )

    results.append({
        "Model": name,
        "Mean R2": np.mean(cv_results["test_r2"]),
        "Mean MAE": np.mean(cv_results["test_mae"]),
        "Mean RMSE": np.mean(cv_results["test_rmse"])
    })

results_df = pd.DataFrame(results).sort_values(
    by="Mean R2", ascending=False
).reset_index(drop=True)

print(results_df)

import pandas as pd

corr = pd.concat([X_train, y_train], axis=1).corr()

print(corr['overall'].sort_values(ascending=False))

"""Running Best Model"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge

final_model = Pipeline([
    ("scaler", StandardScaler()),
    ("model", Ridge(alpha=1.0))
])

final_model.fit(X_train, y_train)

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

y_pred = final_model.predict(X_test)

print("Test R2:", r2_score(y_test, y_pred))
print("Test MAE:", mean_absolute_error(y_test, y_pred))
print("Test RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

"""Prediction Function (For MVP UI)"""

def predict_overall(player_input):
    """
    player_input should be a list in the same order as X_train columns
    """
    prediction = final_model.predict([player_input])
    return prediction[0]

"""Example usage"""

sample_player = [
    25,   # age
    190,  # height_cm
    85,   # weight_kg
    88,   # movement_sprint_speed
    85,   # movement_acceleration
    80,   # movement_agility
    90,   # movement_balance
    92,   # movement_reactions
    70,   # power_jumping
    88,   # power_stamina
    75,   # power_strength
    82,   # defending_standing_tackle
    69,   # goalkeeping_reflexes
    72,   # goalkeeping_diving
    90    # goalkeeping_speed

]

predicted_rating = predict_overall(sample_player)

print("Predicted Overall Rating:", predicted_rating)

"""**Tier Classification**"""

def classify_tier(rating):
    if rating >= 90:
        return "World Class"

    elif rating >= 85:
        return "Elite"

    elif rating >= 75:
        return "Professional"

    elif rating >= 65:
        return "Semi-Pro"

    else:
        return "Developing"

tier = classify_tier(predicted_rating)

print("Player Tier:", tier)

"""**Save Model (For Streamlit Deployment)**"""

import joblib

joblib.dump(final_model, "LR_scout_overall_model.pkl")

joblib.dump(final_model, "LR_scout_overall_model.pkl")

joblib.dump(features, "model_features.pkl")

